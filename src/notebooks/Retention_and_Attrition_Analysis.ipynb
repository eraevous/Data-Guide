{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions\n",
    "<br>ðŸ”¹ Who is an active vs. inactive patient? <br>ðŸ”¹ Are high-value patients leaving? <br>ðŸ”¹ Which patient segments need retention efforts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets\n",
    "<br>ðŸ”¹ All Patient Details <br>ðŸ”¹ Active Patient Details <br>ðŸ”¹ Incurred Charges <br>ðŸ”¹ Guarantor Payments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active vs. Inactive Patient Analysis (Attrition Risk) <br>\n",
    "ðŸ“Œ Goal: Identify patients who haven't returned & optimize outreach efforts.<br>\n",
    "âœ… Steps:<br>\n",
    "\n",
    "Compare active vs. inactive patient lists (who hasnâ€™t visited in 12-24 months?).<br>\n",
    "Segment patients by treatment history, insurance plan, visit frequency.<br>\n",
    "Rank patient segments by retention risk (likelihood to never return).<br>\n",
    "âœ… Datasets Used:<br>\n",
    "All Patient Details, Active Patient Details, Incurred Charges<br>\n",
    "ðŸ“Œ Business Impact:<br>\n",
    "ðŸš€ Enables targeted retention campaigns.<br>\n",
    "ðŸš€ Reduces lost revenue from patient churn.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns   \n",
    "from collections import defaultdict\n",
    "import re\n",
    "import Levenshtein\n",
    "from itertools import combinations\n",
    "from scipy.stats import gmean\n",
    "import profiler as pf\n",
    "import math\n",
    "\n",
    "os.chdir('C:/Users/Admin/Documents/GitHub/Data-Guide')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pull_date = pd.to_datetime('2025-02-18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedure_map = {\n",
    "    \"Crowns\": [\n",
    "        \"Crown - 3/4 porcelain/ceramic\", \"Full Cast HNM Crown\", \"Full Porcelain/Ceramic Crown\",\n",
    "        \"Implant supported crown - porcelain fused to high noble alloys\",\n",
    "        \"Porcelain/HNM Crown\", \"Porcelain/HNM Pontic\", \"Porcelain/Noble Crown\",\n",
    "        \"Retainer crown - porcelain fused to high noble metal\", \"Re-cement or re-bond crown\", \n",
    "        \"Core Buildup w/ Any Pins\",\n",
    "    ],\n",
    "    \n",
    "    \"Prophies\": [\"Prophylaxis - Adult\", \"Prophylaxis - Child\", \"Topical Applic Fluoride Varnish\", \n",
    "        \"Topical Application of Fluoride\", \"Sealant\", \"StellaLife Gel\", \"StellaLife Rinse\"],\n",
    "    \n",
    "    \"Fillings\": [\n",
    "        \"Anterior Resin Composite 1s\", \"Anterior Resin Composite 2s\", \"Anterior Resin Composite 3s\", \n",
    "        \"Anterior Resin Composite 4+s\", \"Posterior Resin Composite 1s\", \"Posterior Resin Composite 2s\", \n",
    "        \"Posterior Resin Composite 3s\", \"Posterior Resin Composite 4+s\",\n",
    "        \"Custom Abutment\"\n",
    "    ],\n",
    "    \n",
    "    \"Imaging\": [\n",
    "        \"2D Oral/Facial Photo Images\", \"Bitewing Four Images\", \"Bitewing Single Image\", \"Bitewing Two Images\",\n",
    "        \"Intraoral - comprehensive series of radiographic images\", \"Intraoral Periapical Add'l\", \n",
    "        \"Intraoral Periapical Images\", \"Panoramic Image\", \"Intraoral â€“ comprehensive series of radiographic images\"\n",
    "    ],\n",
    "    \n",
    "    \"Evaluations\": [\n",
    "        \"Comprehensive Evaluation\", \"Periodic Evaluation\", \"Limited Evaluation\", \"Re-eval - Post-op Office Visit\",\n",
    "        \"Periodontal Evaluation\"\n",
    "    ],\n",
    "    \n",
    "    \"SRP\": [\"Scaling & Root Planing (1-3)\", \"Scaling & Root Planing (4-8)\", \"Scaling in presence of generalized gingival inflammation, full mouth\"],\n",
    "    \n",
    "    \"Perio Maintenance\": [\"Periodontal Maintenance\"],\n",
    "    \n",
    "    \"Appliance\": [\n",
    "        \"Occlusal guard - hard appliance, full arch\", \"Orthodontic Retention\", \n",
    "        \"Replacement of lost or broken retainer - mandibular\", \"Re-cement or re-bond fixed retainer - maxillary\",\n",
    "        \"Recement/bnd inlay/onlay/part\", \"Recemnt/bnd cast/prefab pst/cor\"\n",
    "    ],\n",
    "    \n",
    "    \"Other\": [\n",
    "        \"Bone Replacement Graft\", \"Palliative treatment of dental pain - per visit\",\n",
    "        \"Removal of fixed orthodontic appliances for reasons other than completion of treatment\",\n",
    "        \"Cancelled Appointment\", \"Late cancellation fee\", \"Teeth White - In Office\", \"Teeth White - Take Home\",\n",
    "        \"Diagnostic/Study Models\", \"Editorial change to the descriptor\", \n",
    "        \"Misc Invoice\", \"Routine Extraction\", \n",
    "        \"Remove Coronal Remnants - primary tooth\", \"Limited Occlusal Adjustment\",\n",
    "        \"External Bleaching-Office-Arch\"\n",
    "    ],\n",
    "\n",
    "    \"Dental Wellness Plan\": [\"Dental Wellness Plan\"],\n",
    "    \n",
    "    \"Dentures & Partials\": [\n",
    "        \"Interim Lower Partial Denture\", \"Interim Upper Partial Denture\", \"Lower Partial w/ Resin Base\"\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"C:/Users/Admin/Documents/GitHub/Data-Guide/data_pipeline/transformed_feb_18\" \n",
    "\n",
    "output_dir = \"C:/Users/Admin/Documents/GitHub/Data-Guide/data_pipeline/analyses_feb_18\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Load the data\n",
    "csv_files = {\n",
    "    #\"aged_AR\" : os.path.join(input_dir, \"transformed_aged_AR.csv\"),\n",
    "    #\"aged_AR_long\" : os.path.join(input_dir, \"transformed_aged_AR_long.csv\"),\n",
    "    #\"statement_submission\" : os.path.join(input_dir, \"transformed_statement_submission.csv\"),\n",
    "    #\"integrated_payments\" : os.path.join(input_dir, \"transformed_integrated_payments.csv\"),\n",
    "    #\"billing_statement\" : os.path.join(input_dir, \"billing_statement_report.csv\"),\n",
    "    #\"outstanding_claims\" : os.path.join(input_dir, \"transformed_outstanding_claims.csv\"),\n",
    "    # \"unresolved_claims\" : os.path.join(input_dir, \"unresolved_claims_report.csv\"),\n",
    "    #\"fee_schedule\" : os.path.join(input_dir, \"fee_schedule.csv\"),\n",
    "    #\"openings\" : os.path.join(input_dir,\"openings.csv\"),\n",
    "    #\"schedule\" : os.path.join(input_dir,\"schedule.csv\"),\n",
    "    \"patient_details\" : os.path.join(input_dir, \"transformed_patient_details.csv\"),\n",
    "    \"active_patients\" : os.path.join(input_dir, \"transformed_active_patient_details.csv\"),\n",
    "    #\"processed_payments\": os.path.join(input_dir, \"transformed_processed_payments.csv\"),\n",
    "    #\"payments\": os.path.join(input_dir, \"transformed_payments.csv\"),\n",
    "    \"incurred_charges\": os.path.join(input_dir, \"transformed_incurred_charges.csv\"),\n",
    "    \"transaction_details\" : os.path.join(input_dir, \"transformed_transaction_details.csv\"),\n",
    "    # \"treatment_tracker\" : os.path.join(input_dir, \"ZR - Treatment Tracker.csv\"),\n",
    "    # \"merged_data\" : os.path.join(input_dir, \"merged_data.csv\"),\n",
    "    #'carrier_decision_data' : os.path.join(input_dir, 'Carrier_Decision_Data.csv'),\n",
    "    #'insurance_payment_metrics' : os.path.join(input_dir, 'insurance_payment_metrics.csv'),\n",
    "    \"financial_timeline\" : os.path.join(input_dir, \"financial_timeline.csv\"),\n",
    "    #'time_to_payments' : os.path.join(input_dir, \"time_to_payments.csv\"),\n",
    "}\n",
    " # Load datasets\n",
    "dataframes = {dataset: pd.read_csv(file_path) for dataset, file_path in csv_files.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = dataframes['transaction_details']\n",
    "transactions.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedure_timeline = transactions.loc[transactions['Category'] == 'Procedures',\n",
    "                                    [\"Ascend Patient ID\", \"Category\", 'Date', 'Proc. Description', 'Proc Treatment Area', 'Charges']\n",
    "                                    ].melt(id_vars=[\"Ascend Patient ID\", \"Category\", 'Date', 'Proc. Description', 'Proc Treatment Area'],\n",
    "                                            var_name=\"Var\", \n",
    "                                            value_name=\"Value\"\n",
    "                                            ).drop(axis=1, columns=['Var']\n",
    "                                            ).sort_values([\"Ascend Patient ID\", 'Date']\n",
    "                                                        ).query('Value != 0'\n",
    "                                                                ).groupby([\"Ascend Patient ID\", \"Category\", 'Date', 'Proc. Description']\n",
    "                                                                            ).agg({\n",
    "                                                                                \"Proc Treatment Area\": [\n",
    "                                                                                    (\"Number of Treatment Areas\", lambda x: x.nunique()),\n",
    "                                                                                    (\"Treatment Areas\", lambda x: \", \".join(x.dropna()))\n",
    "                                                                                    ],\n",
    "                                                                                \"Value\": [\n",
    "                                                                                    (\"Value\", lambda x: x.sum())\n",
    "                                                                                    ]\n",
    "                                                                                    }).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedure_timeline.columns = procedure_timeline.columns.map(lambda x: x[1] if x[1] != '' else x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedure_timeline.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedure_timeline[\"proc_group\"] = procedure_timeline[\"Proc. Description\"].apply(lambda x: next((k for k, v in procedure_map.items() if x in v), \"Other\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedure_timeline.groupby(['proc_group']).agg({\n",
    "    'Value': ['sum', 'count']\n",
    "}).sort_values(('Value', 'sum'), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedure_timeline.loc[procedure_timeline['proc_group'] == 'Other', 'Proc. Description'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedure_timeline.loc[procedure_timeline['proc_group'] == 'Other'].groupby(['Proc. Description']).agg({\n",
    "    'Value': ['sum', 'count']\n",
    "}).sort_values(('Value', 'sum'), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_space = procedure_timeline.groupby(['Ascend Patient ID', 'Date']).agg({\n",
    "    'Value': [('Total Charges','sum')],\n",
    "    \"Proc. Description\": [\n",
    "        (\"Number of Procedures\", \"count\"),\n",
    "        (\"Number Distinct Procedures\", \"nunique\"),\n",
    "        (\"Procedures\", lambda x: \", \".join(x))\n",
    "    ],\n",
    "    \"proc_group\": [\n",
    "        (\"Number of Proc Groups\", \"nunique\"),\n",
    "        (\"Groups\", lambda x: \", \".join(sorted(pd.unique(x))))\n",
    "    ]\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_space.columns = state_space.columns.map(lambda x: x[1] if x[1] != '' else x[0])\n",
    "state_space['Date'] = pd.to_datetime(state_space['Date'])\n",
    "\n",
    "state_space = state_space.sort_values(['Ascend Patient ID', 'Date'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_space[\"Prior Groups\"] = state_space.groupby(\"Ascend Patient ID\")[\"Groups\"].shift(1)\n",
    "state_space[\"Next Groups\"] = state_space.groupby(\"Ascend Patient ID\")[\"Groups\"].shift(-1)\n",
    "\n",
    "state_space[\"Prior Date\"] = state_space.groupby(\"Ascend Patient ID\")[\"Date\"].shift(1)\n",
    "state_space[\"Next Date\"] = state_space.groupby(\"Ascend Patient ID\")[\"Date\"].shift(-1)\n",
    "\n",
    "state_space[\"Days Since Prior\"] = (state_space[\"Date\"] - state_space[\"Prior Date\"]).dt.days\n",
    "state_space[\"Days Until Next\"] = (state_space[\"Next Date\"] - state_space[\"Date\"]).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_space['Groups'].value_counts().map(lambda x: 100 *x / state_space.shape[0]).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_space['Groups'].value_counts().map(lambda x: x / state_space.shape[0]).cumsum().head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_space = state_space.groupby(['Groups', 'Next Groups']).agg({\n",
    "    'Total Charges': [('Total Charges', 'sum')],\n",
    "    'Days Until Next' : [('Mean Days Until Next Procedure', lambda x: round(np.nanmean(x), 0))],\n",
    "    'Ascend Patient ID': [('Number of Patients', 'nunique'),\n",
    "                      ('Number of Transitions', 'count'),\n",
    "                      ('Transition Rate', lambda x: x.count() / state_space.shape[0])\n",
    "    ]\n",
    "}).reset_index()\n",
    "\n",
    "transition_space.columns = transition_space.columns.map(lambda x: x[1] if x[1] != '' else x[0])\n",
    "transition_space\n",
    "transition_space.sort_values('Number of Transitions', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = state_space[['Prior Groups', 'Days Since Prior', 'Groups', 'Days Until Next', 'Next Groups', 'Ascend Patient ID']].copy()\n",
    "steps['Next Groups'].fillna('End', inplace=True)\n",
    "steps['Prior Groups'].fillna('Start', inplace=True)\n",
    "\n",
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = steps.loc[:,['Prior Groups', 'Groups', 'Days Since Prior', 'Ascend Patient ID']].copy()\n",
    "right = steps.loc[:,['Groups', 'Next Groups', 'Days Until Next', 'Ascend Patient ID']].copy()\n",
    "\n",
    "left.columns = ['Start', 'End', 'Days', 'ID']\n",
    "right.columns = ['Start', 'End', 'Days', 'ID']\n",
    "\n",
    "transitions = pd.concat([left, right], axis=0).drop_duplicates()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = transitions.groupby(['Start', 'End']).agg({\n",
    "    'Days': [('Average Time Between', lambda x: round(np.nanmean(x), 0)),\n",
    "             ],\n",
    "    'ID' : [('Count', 'count'),\n",
    "            ('Patients', 'nunique'),\n",
    "            #('Transition Rate', lambda x: x.count() / state_space.shape[0])\n",
    "            ],\n",
    "}).reset_index()\n",
    "\n",
    "graph_data.columns = graph_data.columns.map(lambda x: x[1] if x[1] != '' else x[0])\n",
    "graph_data.sort_values('Count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_data = graph_data.groupby('Start').agg({\n",
    "    'Count': ['sum']\n",
    "}).sort_values(('Count', 'sum'), ascending=False).reset_index()\n",
    "node_data.columns = ['Start', 'Total']\n",
    "\n",
    "node_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = graph_data.merge(node_data, on='Start', how='left')\n",
    "end_total = graph_data.loc[graph_data['End'] == 'End', 'Count'].sum()\n",
    "graph_data.loc[graph_data['End'] == 'End', 'Total'] = end_total\n",
    "graph_data['Transition Rate'] = graph_data['Count'] / graph_data['Total']\n",
    "graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.patches import Patch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "class MarkovChainVisualizer:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        self.graph = nx.DiGraph()\n",
    "        self._build_graph()\n",
    "\n",
    "    def _build_graph(self):\n",
    "        \"\"\"Build the directed graph from the DataFrame.\"\"\"\n",
    "        for _, row in self.df.iterrows():\n",
    "            start = row['Start']\n",
    "            end = row['End']\n",
    "            transition_rate = row['Transition Rate']\n",
    "            count = row['Count']\n",
    "            avg_time = row.get('Average Time Between', None)\n",
    "\n",
    "            if not pd.isna(start):\n",
    "                self.graph.add_node(start, count=count)\n",
    "            if not pd.isna(end):\n",
    "                self.graph.add_node(end, count=count)\n",
    "            if not pd.isna(start) and not pd.isna(end):\n",
    "                self.graph.add_edge(start, end, weight=transition_rate, avg_time=avg_time)\n",
    "\n",
    "    def draw_graph(self):\n",
    "        \"\"\"Visualize the Markov Chain using NetworkX, with sorted circular layout and edge color gradient.\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(60, 40))  # <-- Needed for proper axes reference\n",
    "\n",
    "        # --- Define keyword groups and colors in order of priority ---\n",
    "        keyword_groups = [\n",
    "            (['Evaluations', 'Imaging', 'Prophies'], 'skyblue'),\n",
    "            (['Fillings'], 'orange'),\n",
    "            (['SRP'], 'green'),\n",
    "            (['Crowns'], 'red')\n",
    "        ]\n",
    "\n",
    "        def get_node_category(name):\n",
    "            for i, (keywords, color) in enumerate(keyword_groups):\n",
    "                if any(keyword in name for keyword in keywords):\n",
    "                    return i, color\n",
    "            return 999, 'lightgray'  # Default\n",
    "\n",
    "        # --- Sort nodes ---\n",
    "        nodes = self.graph.nodes(data=True)\n",
    "        node_info = []\n",
    "        for name, data in nodes:\n",
    "            priority, color = get_node_category(name)\n",
    "            size = data.get('count', 1)\n",
    "            if name == \"Start\":\n",
    "                priority = -2\n",
    "            elif name == \"End\":\n",
    "                priority = 1000\n",
    "            node_info.append((name, priority, size, color))\n",
    "\n",
    "        sorted_nodes = [name for name, *_ in sorted(node_info, key=lambda x: (x[1], -x[2], x[0]))]\n",
    "\n",
    "        # --- Sorted layout ---\n",
    "        pos = nx.circular_layout(self.graph)\n",
    "        pos = {name: pos[name] for name in sorted_nodes if name in pos}\n",
    "\n",
    "        node_sizes = [math.log10(self.graph.nodes[n].get('count', 1)) * 1200 for n in sorted_nodes]\n",
    "        node_colors = [get_node_category(n)[1] for n in sorted_nodes]\n",
    "\n",
    "        nx.draw_networkx_nodes(\n",
    "            self.graph, pos,\n",
    "            nodelist=sorted_nodes,\n",
    "            node_color=node_colors,\n",
    "            node_size=node_sizes,\n",
    "            edgecolors='black',\n",
    "            ax=ax  # <-- explicitly attach to ax\n",
    "        )\n",
    "\n",
    "        # --- Edge coloring logic ---\n",
    "        edges = list(self.graph.edges(data=True))\n",
    "        avg_times = [d['avg_time'] for (_, _, d) in edges if pd.notna(d.get('avg_time')) and d['avg_time'] > 0]\n",
    "        if avg_times:\n",
    "            log_times = np.log(avg_times)\n",
    "            norm = mcolors.Normalize(vmin=min(log_times), vmax=max(log_times))\n",
    "        else:\n",
    "            norm = mcolors.Normalize(vmin=0, vmax=1)\n",
    "        cmap = cm.get_cmap('viridis')\n",
    "\n",
    "        for u, v, d in edges:\n",
    "            weight = d.get('weight', 0.01) * 100\n",
    "            avg_time = d.get('avg_time')\n",
    "            if pd.notna(avg_time) and avg_time > 0:\n",
    "                log_val = np.log(avg_time)\n",
    "                color = cmap(norm(log_val))\n",
    "            else:\n",
    "                color = 'gray'\n",
    "\n",
    "            nx.draw_networkx_edges(\n",
    "                self.graph, pos,\n",
    "                edgelist=[(u, v)],\n",
    "                width=0 + math.log10(weight) * 5,\n",
    "                edge_color=[color],\n",
    "                alpha=0.8,\n",
    "                arrows=True,\n",
    "                arrowstyle='-|>',\n",
    "                arrowsize=30,\n",
    "                min_source_margin=15,\n",
    "                min_target_margin=25,\n",
    "                connectionstyle='arc3,rad=0.2',\n",
    "                ax=ax\n",
    "            )\n",
    "\n",
    "        nx.draw_networkx_labels(self.graph, pos, font_size=10, font_weight='bold', ax=ax)\n",
    "\n",
    "        # --- Colorbar: fix for manual edges ---\n",
    "        if avg_times:\n",
    "            sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "            sm.set_array([])  # required to avoid warning\n",
    "            cbar = fig.colorbar(sm, ax=ax, fraction=0.02, pad=0.01)\n",
    "            cbar.set_label(\"Log(Average Days Between)\", fontsize=14)\n",
    "\n",
    "        # --- Legend for node color categories ---\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [\n",
    "            Patch(facecolor='skyblue', edgecolor='black', label='Evaluations / Imaging / Prophies'),\n",
    "            Patch(facecolor='orange', edgecolor='black', label='Fillings'),\n",
    "            Patch(facecolor='green', edgecolor='black', label='SRP'),\n",
    "            Patch(facecolor='red', edgecolor='black', label='Crowns'),\n",
    "            Patch(facecolor='lightgray', edgecolor='black', label='Uncategorized')\n",
    "        ]\n",
    "        ax.legend(\n",
    "            handles=legend_elements,\n",
    "            title=\"Node Categories\",\n",
    "            loc='upper right',\n",
    "            fontsize=12,\n",
    "            title_fontsize=13\n",
    "        )\n",
    "\n",
    "        ax.set_title(\"Markov Chain of Patient Procedure Transitions\", fontsize=20)\n",
    "        ax.set_axis_off()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage (assuming df is your DataFrame with transition data)\n",
    "import pandas as pd\n",
    "\n",
    "df = graph_data.copy()  # Load your data\n",
    "viz = MarkovChainVisualizer(df)\n",
    "viz.draw_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define keyword groups and colors in order of priority ---\n",
    "keyword_groups = [\n",
    "    (['Crowns'], 'Crowns'),\n",
    "    (['SRP'], 'SRP'),\n",
    "    (['Fillings'], 'Fillings'),\n",
    "    (['Evaluations', 'Imaging', 'Prophies'], 'Evaluations / Imaging / Prophies'),\n",
    "    (['Start'], 'Start'),\n",
    "    (['End'], 'End')\n",
    "]\n",
    "\n",
    "def get_node_category(name):\n",
    "    for i, (keywords, mapping) in enumerate(keyword_groups):\n",
    "        if any(keyword in name for keyword in keywords):\n",
    "            return mapping\n",
    "    return 'Other'  # Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions_simplified = transitions.copy()\n",
    "\n",
    "transitions_simplified['Start_simple'] = transitions_simplified['Start'].apply(get_node_category)\n",
    "transitions_simplified['End_simple'] = transitions_simplified['End'].apply(get_node_category)\n",
    "\n",
    "transitions_simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions_simplified['Start'] = transitions_simplified['Start'].apply(get_node_category)\n",
    "transitions_simplified['End'] = transitions_simplified['End'].apply(get_node_category)\n",
    "\n",
    "transitions_simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_simplified = transitions_simplified.groupby(['Start', 'End']).agg({\n",
    "    'Days': [('Average Time Between', lambda x: round(np.nanmean(x), 0)),\n",
    "             ],\n",
    "    'ID' : [('Count', 'count'),\n",
    "            ('Patients', 'nunique'),\n",
    "            #('Transition Rate', lambda x: x.count() / state_space.shape[0])\n",
    "            ],\n",
    "}).reset_index()\n",
    "\n",
    "graph_data_simplified.columns = graph_data_simplified.columns.map(lambda x: x[1] if x[1] != '' else x[0])\n",
    "graph_data_simplified.sort_values('Count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_data_simplified = graph_data_simplified.sort_values('Count', ascending=False).groupby('Start').agg({\n",
    "    'Count': ['sum']\n",
    "}).sort_values(('Count', 'sum'), ascending=False).reset_index()\n",
    "node_data_simplified.columns = ['Start', 'Total']\n",
    "\n",
    "node_data_simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_simplified = graph_data_simplified.merge(node_data_simplified, on='Start', how='left')\n",
    "end_total = graph_data_simplified.loc[graph_data_simplified['End'] == 'End', 'Count'].sum()\n",
    "graph_data_simplified.loc[graph_data_simplified['End'] == 'End', 'Total'] = end_total\n",
    "graph_data_simplified['Transition Rate'] = graph_data_simplified['Count'] / graph_data_simplified['Total']\n",
    "graph_data_simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = graph_data_simplified.copy()  # Load your data\n",
    "viz = MarkovChainVisualizer(df)\n",
    "viz.draw_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
